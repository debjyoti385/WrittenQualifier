\section{Part A: System Architecture  Spatio-Temporal Analysis for Health Analysis:}
\label{part_a}
A comprehensive system for spatio-temporal analysis requires the following components which can be braodly categorized based on their operations:
% \vspace{-4mm}

\begin{itemize}
  \item \textbf{Data Ingestion}
    {\em
    \begin{itemize}
      \item[-] Data Collection Module
    \end{itemize}
    }
  \item \textbf{Data Enrichment}
    {\em
    \begin{itemize}
    \item[-] Data Cleaning Module
    \item[-] Location Extraction Module
    \end{itemize}
    }
  \item \textbf{AI/ML Models}
    {\em
    \begin{itemize}
      \item[-] Tweet/Document Classification Module
      \item[-] Sentiment Analysis Module
      \item[-] Image Classification Module (optional)
    \end{itemize}
    }
  \item \textbf{Data Storage}
  \item \textbf{Analytics Processing Engine:}
    {\em
    \begin{itemize}
      \item[-] Realtime Data Aggregation Support
      \item[-] Spatio-temporal Query Support
    \end{itemize}
    }
  \item \textbf{Visualization}
    {\em
    \begin{itemize}
      \item[-] Realtime Dashboard
      \item[-] Dynamic Data Visualization Module
    \end{itemize}
    }
\end{itemize}

In the follwong part I will throw some light on each component and discuss about challenges if they have any.

\subsection{Data Ingestion}
\Paragraph{Data Collection Module:}
Twitter is biggest social media data source for researchers. Twitter's 1\% sample data stream API is the most common approach for data collection. Twitter statistics reveals that only 0.85\% of tweets in the stream is geotagged \cite{sloan2013knowing} which is significantly lower. Utmost effort and care should be taken to collect more geotagged data. Twitter's location based API should be used for such purpose.

\paragraph{Challenges:}
Collecting data from location based API or any other keyword based search API are restrictive in nature with request limit per hour.
Evading this problem might be challenging with limit resources. Multiple number of data collection servers collecting mutually exclusive geographical region can help to collect more geotagged data. For some social media sites it is almost necessary to use proxy network to avoid IP block.

\subsection{Data Enrichment:}
\Paragraph{Data Cleaning Module:}
Data collected from social media often needs to be cleaned (e.g. tokenize, language filter etc.) for processing. The common scenarios for cleaning operations are {\em(i) filtering english tweets, (ii) removing emoticons (iii) keywords extraction etc. }

\vspace{-2mm}
\paragraph{Challenges:} There are many good tools for data cleaning. The main concerns are {\em(i) which library tools to use for desired result. (ii) the library should have high processing throughput}

\Paragraph{Location Extraction Module}
As mentioned earlier that percentage of geotagged tweet is not high. However, a lot of attempts have been made to predict the location of the tweet based on user activity and history.  Geotagging users is now a well studied problem and it has a median error of 6.38 km which might not be very significant for our analysis\cite{compton2014geotagging}.

\vspace{-2mm}
\paragraph{Challenges:}
Need to collecting more data about users. If we are interested in home location of users then the above mentioned \cite{compton2014geotagging} technique is fine. However if we want the dynamic location as the users move or travel then it is a challenging problem.


\subsection{AI/ML Models:}
\Paragraph{Tweets/Document Classification Model:}
In order to distinguish between relevant (e.g. health, food, disease etc.) and  non relevant tweets/documents we a document classification component. Unsupervised methods like topic modeling with LDA \cite{}, pLSA \cite{} and phrase LDA \cite{} and modified versions of them can help in classification problem. However, microblogs classification for targeted topic needs further attention. In our work \cite{compasskdd} for {\em Spatio-temporal Sentiment Analysis for US Election}, we used political and non-poilitical tweet classification in a semi-supervised approach. The semi-supervised approach starts by creating training data for classification. Topic modeling act as a bootstrap method for creating training data that helps in learning tweet classification through context. This semi-supervised approach proved to be more robust \cite{compasskdd}.

\vspace{-2mm}
\paragraph{Challenges:}
The semi-supervised approach used in \cite{compasskdd} have not been used yet for classification in health realted topics. Previous works like {\em topic model for ailment} \cite{} are extension of topic modeling with LDA and specially descigned for ailment tweet discovery. Remodeling semi-supervised classification for disease and health are yet to experiment and might face challenges.
For example tweets like {"I feel like I'm going to die of Bieber Fever, No Joke!"} and  {\em "Web design class gives me a huge headache everytime"} both tweets does not talk about health condition. Hence learning context of words is desirable approach.

\Paragraph{Sentiment Analysis Model:}

\vspace{-2mm}
\paragraph{Challenges:}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
